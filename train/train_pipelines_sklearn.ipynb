{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce944d7-5319-4f82-a6e2-6701851c3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145207bb-f67b-44ed-8ffb-d63a6533e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85a3043-fdcf-4f0c-8547-a8907f5805c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINIO_ACCESS_KEY test_menio_access_key\n",
      "MINIO_SECRET_KEY test_minio_secret_key\n",
      "MLFLOW_TRACKING_URI \"postgresql://mlflow:mlflow_pass@postgres:5432/mlflow\"\n",
      "MLFLOW_S3_ENDPOINT_URL http://minio:9000\n",
      "MLFLOW_S3_IGNORE_TLS true\n",
      "MLFLOW_BUCKET_NAME mlflow-artifacts\n",
      "MLFLOW_SERVER http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "AWS_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY\", None); \n",
    "AWS_SECRET_KEY = os.getenv(\"AWS_SECRET_KEY\", None); \n",
    "\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", None); \n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", None); \n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", None); \n",
    "MLFLOW_S3_ENDPOINT_URL = os.getenv(\"MLFLOW_S3_ENDPOINT_URL\", None); \n",
    "MLFLOW_S3_IGNORE_TLS = os.getenv(\"MLFLOW_S3_IGNORE_TLS\", None); \n",
    "MLFLOW_BUCKET_NAME = os.getenv(\"MLFLOW_BUCKET_NAME\", None); \n",
    "MLFLOW_SERVER = os.getenv(\"MLFLOW_SERVER\", None);\n",
    "MLFLOW_EXPERIMENT_NAME = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"mlzoomcamp\");\n",
    "\n",
    "\n",
    "print(\"MINIO_ACCESS_KEY\", MINIO_ACCESS_KEY)\n",
    "print(\"MINIO_SECRET_KEY\", MINIO_SECRET_KEY)\n",
    "print(\"MLFLOW_TRACKING_URI\", MLFLOW_TRACKING_URI)\n",
    "print(\"MLFLOW_S3_ENDPOINT_URL\", MLFLOW_S3_ENDPOINT_URL)\n",
    "print(\"MLFLOW_S3_IGNORE_TLS\", MLFLOW_S3_IGNORE_TLS)\n",
    "print(\"MLFLOW_BUCKET_NAME\", MLFLOW_BUCKET_NAME)\n",
    "print(\"MLFLOW_SERVER\", MLFLOW_SERVER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead32ec8-4b96-40a0-aa4e-178e919e88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-21 16:27:21--  https://raw.githubusercontent.com/jelambrar96-datatalks/house-price-predictor/refs/heads/main/dataset/train.csv\n",
      "185.199.110.133, 185.199.108.133, 185.199.109.133, ...tent.com)... \n",
      "connected. to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 460676 (450K) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>] 449.88K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-01-21 16:27:22 (4.22 MB/s) - ‘train.csv’ saved [460676/460676]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train.csv \"https://raw.githubusercontent.com/jelambrar96-datatalks/house-price-predictor/refs/heads/main/dataset/train.csv\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d322763b-a81b-4692-aeca-b6733278762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c716e3-9ef8-4ff1-be12-a8e1c4f462d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert camelCase or PascalCase to snake_case\n",
    "def to_snake_case(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "df_full.columns = [to_snake_case(col) for col in df_full.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937f6de5-95e0-4750-b6c4-3d8012bb12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(\n",
    "    columns=[\"id\", \"alley\", \"pool_qc\", \"fence\", \"misc_feature\", \"mas_vnr_type\", \"fireplace_qu\", \"lot_frontage\"],\n",
    "    inplace=True\n",
    "    )\n",
    "df_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe4191d-e9d1-42fb-b615-b820d2a50762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 73)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af6ecda-d289-4fae-afbb-81d0ae44e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = \"sale_price\"\n",
    "\n",
    "df_full[TARGET_COLUMN] = np.log1p(df_full[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6429f436-3e89-4895-9400-8e7bfdc7e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00dee038-6a62-46c1-976f-bbe708e3c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(\n",
    "    df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_full_train = (df_full_train[TARGET_COLUMN]).astype('int').values\n",
    "y_test = (df_test[TARGET_COLUMN]).astype('int').values\n",
    "\n",
    "del df_full_train[TARGET_COLUMN]\n",
    "del df_test[TARGET_COLUMN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e478e9-e177-4aec-ad3a-ee199a73cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = df_full_train.select_dtypes(include=['number']).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_full_train[numerical_cols] = scaler.fit_transform(df_full_train[numerical_cols])\n",
    "df_test[numerical_cols]       = scaler.fit_transform(df_test[numerical_cols])\n",
    "\"\"\" \n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694f1e19-1ad0-48c6-9f4b-8848f2935914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_cols = df_full_train.select_dtypes(include=['object']).columns\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "full_train_dict = df_full_train.to_dict(orient='records')\n",
    "X_full_train = dv.fit_transform(full_train_dict)\n",
    "\n",
    "test_dict = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c5c8949-cabe-4905-ba43-bde2efac6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "SCORING = \"neg_root_mean_squared_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baec7c1-8f8c-47c1-a3e3-27ca79b8c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='s3://mlflow-artifacts/experiments/', creation_time=1737476847625, experiment_id='141662139641609146', last_update_time=1737476847625, lifecycle_stage='active', name='mlzoomcamp', tags={}>\n",
      "141662139641609146\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "# mlflow.sklearn.autolog()\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER)\n",
    "# MLFLOW_EXPERIMENT_NAME = f'ml-zoomcamp-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "\n",
    "list_experiments = mlflow.search_experiments(\n",
    "    filter_string=f\"name = '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "if len(list_experiments) == 0:\n",
    "    mlflow.create_experiment(\n",
    "        MLFLOW_EXPERIMENT_NAME,\n",
    "        artifact_location=f\"s3://{MLFLOW_BUCKET_NAME}/experiments/\") \n",
    "    list_experiments = mlflow.search_experiments(\n",
    "        filter_string=f\"name = '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "mlflow_experiment = list_experiments[0]\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "print(mlflow_experiment)\n",
    "print(mlflow_experiment.experiment_id)\n",
    "\n",
    "# print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "def print_model_version_info(mv):\n",
    "    print(f\"Name: {mv.name}\")\n",
    "    print(f\"Version: {mv.version}\")\n",
    "    print(f\"Source: {mv.source}\")\n",
    "\n",
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107c7822-94b1-4e18-9761-8f45c99fe944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_params = {\n",
    "    'dict_vectorizer__sparse': [False],\n",
    "    'linear_regression__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "linear_regession_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "linear_regression_grid_search = GridSearchCV(\n",
    "    estimator=linear_regession_pipeline,\n",
    "    param_grid=linear_regression_params,\n",
    "    n_jobs=-1,\n",
    "    scoring=SCORING\n",
    ")\n",
    "linear_regression_grid_search_fitted = linear_regression_grid_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_linear_regression_estimator = linear_regression_grid_search_fitted.best_estimator_\n",
    "best_linear_regression_params = linear_regression_grid_search_fitted.best_params_\n",
    "best_linear_regression_score = linear_regression_grid_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3854b782-4523-4408-be3c-da7c95b5708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:27:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: linear-regression-staging-20250121-162740, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: linear-regression-production\n",
      "Version: 1\n",
      "Source: models:/linear-regression-staging-20250121-162740/1\n",
      "🏃 View run linear-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/420ffd960e5e4127b9dbdf34f921af61\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'linear-regression-production'.\n",
      "Copied version '1' of model 'linear-regression-staging-20250121-162740' to version '1' of model 'linear-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"linear-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_linear_regression_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_linear_regression_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_linear_regression_score)\n",
    "    mlflow.sklearn.log_model(best_linear_regression_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'linear-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"linear-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a0c7f0-d81f-48c0-98dc-2aab114b1597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+01, tolerance: 2.367e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+01, tolerance: 2.334e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e+01, tolerance: 2.408e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+01, tolerance: 2.400e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+01, tolerance: 2.400e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e+01, tolerance: 2.334e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+01, tolerance: 2.367e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e+01, tolerance: 2.346e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+01, tolerance: 2.408e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+01, tolerance: 2.346e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.225e+01, tolerance: 2.965e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_params = {\n",
    "    'dict_vectorizer__sparse': [False],\n",
    "    'lasso_regression__alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "lasso_regession_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('lasso_regression', Lasso())\n",
    "])\n",
    "\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=lasso_regession_pipeline,\n",
    "    param_grid=lasso_params,\n",
    "    n_jobs=-1,\n",
    "    scoring=SCORING\n",
    ")\n",
    "lasso_grid_search_fitted = lasso_grid_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_lasso_estimator = lasso_grid_search_fitted.best_estimator_\n",
    "best_lasso_params = lasso_grid_search_fitted.best_params_\n",
    "best_lasso_score = lasso_grid_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "211c3a3f-95a3-49e1-a56a-1e066aaf0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:27:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lasso-regression-staging-20250121-162746, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lasso-regression-production\n",
      "Version: 1\n",
      "Source: models:/lasso-regression-staging-20250121-162746/1\n",
      "🏃 View run lasso-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/6bafca0011d24513b26c38587d1f82ec\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'lasso-regression-production'.\n",
      "Copied version '1' of model 'lasso-regression-staging-20250121-162746' to version '1' of model 'lasso-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"lasso-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_lasso_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_lasso_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_lasso_score)\n",
    "    mlflow.sklearn.log_model(best_lasso_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'lasso-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"lasso-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe8bdec-a284-4ecc-b942-afdc6e090e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_params = {\n",
    "    'dict_vectorizer__sparse': [False],\n",
    "    'decision_tree_regressor__criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    'decision_tree_regressor__max_depth': [None, 5, 10, 20],\n",
    "    'decision_tree_regressor__min_samples_split': [2, 5, 10],\n",
    "    'decision_tree_regressor__min_samples_leaf': [1, 5, 10],\n",
    "    'decision_tree_regressor__max_features': [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    'decision_tree_regressor__random_state': [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "decision_tree_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('decision_tree_regressor', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "decision_tree_search = RandomizedSearchCV(\n",
    "    estimator=decision_tree_pipeline,\n",
    "    param_distributions=decision_tree_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scoring=SCORING\n",
    ")\n",
    "\n",
    "decision_tree_search_fitted = decision_tree_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_decision_tree_estimator = decision_tree_search_fitted.best_estimator_\n",
    "best_decision_tree_params = decision_tree_search_fitted.best_params_\n",
    "best_decision_tree_score = decision_tree_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af0623a-8e01-47b6-861f-360876a3c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:27:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: decision-tree-regression-staging-20250121-162751, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: decision-tree-regression-production\n",
      "Version: 1\n",
      "Source: models:/decision-tree-regression-staging-20250121-162751/1\n",
      "🏃 View run decision-tree-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/97c73d3fb9bc4650a51949254d9bef12\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'decision-tree-regression-production'.\n",
      "Copied version '1' of model 'decision-tree-regression-staging-20250121-162751' to version '1' of model 'decision-tree-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"decision-tree-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_decision_tree_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_decision_tree_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_decision_tree_score)\n",
    "    mlflow.sklearn.log_model(best_decision_tree_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'decision-tree-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"decision-tree-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a69bb02-7d23-4a1f-b376-fa68389f76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 448, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan -0.36681957 -0.28991258 -0.38055692 -0.44780378 -0.34704875\n",
      " -0.52669727         nan -0.36713796         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_params = {\n",
    "    \"dict_vectorizer__sparse\": [False],\n",
    "    \"random_forest_regressor__n_estimators\": [10, 50, 100, 200],\n",
    "    \"random_forest_regressor__max_depth\": [None, 5, 10, 20],\n",
    "    \"random_forest_regressor__min_samples_split\": [2, 5, 10],\n",
    "    \"random_forest_regressor__min_samples_leaf\": [1, 5, 10],\n",
    "    \"random_forest_regressor__max_features\": [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    \"random_forest_regressor__bootstrap\": [True, False],\n",
    "    \"random_forest_regressor__oob_score\": [True, False],\n",
    "    \"random_forest_regressor__criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    \"random_forest_regressor__ccp_alpha\": [0.0, 0.1, 0.2],\n",
    "    \"random_forest_regressor__random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('random_forest_regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "random_forest_search = RandomizedSearchCV(\n",
    "    estimator=random_forest_pipeline,\n",
    "    param_distributions=random_forest_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scoring=SCORING\n",
    ")\n",
    "random_forest_search_fitted = random_forest_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_random_forest_estimator = random_forest_search_fitted.best_estimator_\n",
    "best_random_forest_params = random_forest_search_fitted.best_params_\n",
    "best_random_forest_score = random_forest_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d625c7-2b48-4bfc-9b70-10b3ff9950b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:30:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-staging-20250121-163002, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: random-forest-regression-production\n",
      "Version: 1\n",
      "Source: models:/random-forest-staging-20250121-163002/1\n",
      "🏃 View run random-forest-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/9b7e031483f8462ca02b2f0669dd43ee\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'random-forest-regression-production'.\n",
      "Copied version '1' of model 'random-forest-staging-20250121-163002' to version '1' of model 'random-forest-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"random-forest-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_random_forest_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_random_forest_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_random_forest_score)\n",
    "    mlflow.sklearn.log_model(best_random_forest_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'random-forest-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"random-forest-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4430f5b-e207-4be1-840a-201df5f56d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaboost_regressor_params = {\n",
    "    \"dict_vectorizer__sparse\": [False],\n",
    "    \"adaboost_regressor__learning_rate\": [0.01, 0.1, 1],\n",
    "    \"adaboost_regressor__n_estimators\": [10, 50, 100, 200],\n",
    "    \"adaboost_regressor__loss\": [\"linear\", \"square\", \"exponential\"],\n",
    "    \"adaboost_regressor__estimator\": [\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        # DecisionTreeRegressor(**best_decision_tree_params),\n",
    "        # RandomForestRegressor(**best_random_forest_params)\n",
    "    ],\n",
    "    \"adaboost_regressor__random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "adaboost_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('adaboost_regressor', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "adaboost_regressor_search = RandomizedSearchCV(\n",
    "    estimator=adaboost_pipeline,\n",
    "    param_distributions=adaboost_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scoring=SCORING\n",
    ")\n",
    "adaboost_regressor_search_fitted = adaboost_regressor_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_adaboost_regressor_estimator = adaboost_regressor_search_fitted.best_estimator_\n",
    "best_adaboost_regressor_params = adaboost_regressor_search_fitted.best_params_\n",
    "best_adaboost_regressor_score = adaboost_regressor_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cf1aa1f-ab8a-43ce-8d46-35c397c2ca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:39:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: adaboost-regression-staging-20250121-163925, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: adaboost-regression-production\n",
      "Version: 1\n",
      "Source: models:/adaboost-regression-staging-20250121-163925/1\n",
      "🏃 View run adaboost-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/d3eac55f4ee341988b878370d21f735a\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'adaboost-regression-production'.\n",
      "Copied version '1' of model 'adaboost-regression-staging-20250121-163925' to version '1' of model 'adaboost-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"adaboost-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_adaboost_regressor_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_adaboost_regressor_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_adaboost_regressor_score)\n",
    "    mlflow.sklearn.log_model(best_adaboost_regressor_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'adaboost-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"adaboost-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25ecc743-5ee3-4381-ba59-ff3ddeb5047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan -0.3045406          nan         nan -0.29143904 -0.69009387\n",
      " -0.30198658         nan -0.29531664 -0.36306214]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gradientboost_regressor_params = {\n",
    "    \"dict_vectorizer__sparse\": [False],\n",
    "    \"gradientboost_regressor__learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"gradientboost_regressor__n_estimators\": [50, 100, 200],\n",
    "    \"gradientboost_regressor__max_depth\": [3, 5, 7],\n",
    "    \"gradientboost_regressor__min_samples_split\": [2, 5, 10],\n",
    "    \"gradientboost_regressor__min_samples_leaf\": [1, 2, 4],\n",
    "    \"gradientboost_regressor__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"gradientboost_regressor__subsample\": [1.0, 0.8, 0.5],\n",
    "    \"gradientboost_regressor__loss\": [\"squared_error\", \"absolute_error\", \"huber\"],\n",
    "    \"gradientboost_regressor__alpha\": [0.5, 0.75, 0.9],\n",
    "    \"gradientboost_regressor__random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "grandientboost_regressor_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('gradientboost_regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "gradientboost_regressor_search = RandomizedSearchCV(\n",
    "    estimator=grandientboost_regressor_pipeline,\n",
    "    param_distributions=gradientboost_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scoring=SCORING\n",
    ")\n",
    "gradientboost_regressor_search_fitted = gradientboost_regressor_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "\n",
    "best_gradientboost_regressor_estimator = gradientboost_regressor_search_fitted.best_estimator_\n",
    "best_gradientboost_regressor_params = gradientboost_regressor_search_fitted.best_params_\n",
    "best_gradientboost_regressor_score = gradientboost_regressor_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51b657c-3dc6-4b62-8d12-727767a13dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:39:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gradientboost-regression-staging-20250121-163934, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gradientboost-regression-production\n",
      "Version: 1\n",
      "Source: models:/gradientboost-regression-staging-20250121-163934/1\n",
      "🏃 View run gradientboost-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/5636015782f2442f9b6125821d127878\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'gradientboost-regression-production'.\n",
      "Copied version '1' of model 'gradientboost-regression-staging-20250121-163934' to version '1' of model 'gradientboost-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"gradientboost-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_gradientboost_regressor_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_gradientboost_regressor_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_gradientboost_regressor_score)\n",
    "    mlflow.sklearn.log_model(best_gradientboost_regressor_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'gradientboost-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"gradientboost-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48530754-21e4-46ee-b4f4-7a4b34a26a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor_params = {\n",
    "    'dict_vectorizer__sparse': [False],\n",
    "    'mlp_regressor__hidden_layer_sizes': [(32,), (64,), (128,)],\n",
    "    'mlp_regressor__activation': ['relu', 'tanh', 'logistic'],\n",
    "    'mlp_regressor__solver': ['lbfgs', 'adam'],\n",
    "    'mlp_regressor__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'mlp_regressor__batch_size': ['auto', 200],\n",
    "    'mlp_regressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'mlp_regressor__power_t': [0.5, 1.0, 2.0],\n",
    "    'mlp_regressor__max_iter': [500, 1000, 1500],\n",
    "    'mlp_regressor__early_stopping': [True, False],\n",
    "    'mlp_regressor__validation_fraction': [0.2, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "mlp_regressor_pipeline = Pipeline([\n",
    "    ('dict_vectorizer', DictVectorizer()),\n",
    "    ('mlp_regressor', MLPRegressor())\n",
    "])\n",
    "\n",
    "mlp_regressor_search = RandomizedSearchCV(\n",
    "    estimator=mlp_regressor_pipeline,\n",
    "    param_distributions=mlp_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scoring=SCORING\n",
    ")\n",
    "mlp_regressor_search_fitted = mlp_regressor_search.fit(full_train_dict, y_full_train)\n",
    "\n",
    "best_mlp_regressor_estimator = mlp_regressor_search_fitted.best_estimator_\n",
    "best_mlp_regressor_params = mlp_regressor_search_fitted.best_params_\n",
    "best_mlp_regressor_score = mlp_regressor_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "179873b6-0c25-45ad-b24b-89300a063b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/01/21 16:42:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mlp-regression-staging-20250121-164259, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlp-regression-production\n",
      "Version: 1\n",
      "Source: models:/mlp-regression-staging-20250121-164259/1\n",
      "🏃 View run mlp-regression at: http://mlflow:5000/#/experiments/141662139641609146/runs/a1ea62ae66974c0cb2b40e6c27ca04f6\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/141662139641609146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'mlp-regression-production'.\n",
      "Copied version '1' of model 'mlp-regression-staging-20250121-164259' to version '1' of model 'mlp-regression-production'.\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "with mlflow.start_run(\n",
    "    experiment_id=mlflow_experiment.experiment_id,\n",
    "    run_name=\"mlp-regression\") as run:\n",
    "    #\n",
    "    y_test_pred = best_mlp_regressor_estimator.predict(test_dict)\n",
    "    rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    signature = infer_signature(test_dict, y_test_pred)    \n",
    "    # \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params(best_mlp_regressor_params)\n",
    "    mlflow.log_metric(f'{SCORING}', best_mlp_regressor_score)\n",
    "    mlflow.sklearn.log_model(best_mlp_regressor_estimator, \"model\", signature=signature)\n",
    "\n",
    "    src_name = f'mlp-regression-staging-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    client.create_registered_model(src_name)\n",
    "    src_uri = f\"runs:/{run.info.run_id}/sklearn-model\"\n",
    "    mv_src = client.create_model_version(src_name, src_uri, run.info.run_id)\n",
    "    \n",
    "    # Copy the source model version into a new registered model\n",
    "    dst_name = \"mlp-regression-production\"\n",
    "    src_model_uri = f\"models:/{mv_src.name}/{mv_src.version}\"\n",
    "    mv_copy = client.copy_model_version(src_model_uri, dst_name)\n",
    "    print_model_version_info(mv_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
