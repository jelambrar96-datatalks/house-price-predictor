{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce944d7-5319-4f82-a6e2-6701851c3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145207bb-f67b-44ed-8ffb-d63a6533e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85a3043-fdcf-4f0c-8547-a8907f5805c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINIO_ACCESS_KEY test_menio_access_key\n",
      "MINIO_SECRET_KEY test_minio_secret_key\n",
      "MLFLOW_TRACKING_URI \"postgresql://mlflow:mlflow_pass@postgres:5432\"\n",
      "MLFLOW_S3_ENDPOINT_URL http://minio:9000\n",
      "MLFLOW_S3_IGNORE_TLS true\n",
      "MLFLOW_BUCKET_NAME mlflow-artifacts\n",
      "MLFLOW_SERVER http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", None); \n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", None); \n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", None); \n",
    "MLFLOW_S3_ENDPOINT_URL = os.getenv(\"MLFLOW_S3_ENDPOINT_URL\", None); \n",
    "MLFLOW_S3_IGNORE_TLS = os.getenv(\"MLFLOW_S3_IGNORE_TLS\", None); \n",
    "MLFLOW_BUCKET_NAME = os.getenv(\"MLFLOW_BUCKET_NAME\", None); \n",
    "MLFLOW_SERVER = os.getenv(\"MLFLOW_SERVER\", None); \n",
    "\n",
    "print(\"MINIO_ACCESS_KEY\", MINIO_ACCESS_KEY)\n",
    "print(\"MINIO_SECRET_KEY\", MINIO_SECRET_KEY)\n",
    "print(\"MLFLOW_TRACKING_URI\", MLFLOW_TRACKING_URI)\n",
    "print(\"MLFLOW_S3_ENDPOINT_URL\", MLFLOW_S3_ENDPOINT_URL)\n",
    "print(\"MLFLOW_S3_IGNORE_TLS\", MLFLOW_S3_IGNORE_TLS)\n",
    "print(\"MLFLOW_BUCKET_NAME\", MLFLOW_BUCKET_NAME)\n",
    "print(\"MLFLOW_SERVER\", MLFLOW_SERVER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead32ec8-4b96-40a0-aa4e-178e919e88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-12 16:43:43--  https://raw.githubusercontent.com/jelambrar96-datatalks/house-price-predictor/refs/heads/main/dataset/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 460676 (450K) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>] 449.88K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-01-12 16:43:43 (5.25 MB/s) - ‘train.csv’ saved [460676/460676]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train.csv \"https://raw.githubusercontent.com/jelambrar96-datatalks/house-price-predictor/refs/heads/main/dataset/train.csv\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d322763b-a81b-4692-aeca-b6733278762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c716e3-9ef8-4ff1-be12-a8e1c4f462d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert camelCase or PascalCase to snake_case\n",
    "def to_snake_case(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "df_full.columns = [to_snake_case(col) for col in df_full.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937f6de5-95e0-4750-b6c4-3d8012bb12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(\n",
    "    columns=[\"id\", \"alley\", \"pool_qc\", \"fence\", \"misc_feature\", \"mas_vnr_type\", \"fireplace_qu\", \"lot_frontage\"],\n",
    "    inplace=True\n",
    "    )\n",
    "df_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe4191d-e9d1-42fb-b615-b820d2a50762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 73)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af6ecda-d289-4fae-afbb-81d0ae44e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = \"sale_price\"\n",
    "\n",
    "df_full[TARGET_COLUMN] = np.log1p(df_full[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6429f436-3e89-4895-9400-8e7bfdc7e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00dee038-6a62-46c1-976f-bbe708e3c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(\n",
    "    df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_full_train = (df_full_train[TARGET_COLUMN]).astype('int').values\n",
    "y_test = (df_test[TARGET_COLUMN]).astype('int').values\n",
    "\n",
    "del df_full_train[TARGET_COLUMN]\n",
    "del df_test[TARGET_COLUMN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e478e9-e177-4aec-ad3a-ee199a73cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = df_full_train.select_dtypes(include=['number']).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_full_train[numerical_cols] = scaler.fit_transform(df_full_train[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "694f1e19-1ad0-48c6-9f4b-8848f2935914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_cols = df_full_train.select_dtypes(include=['object']).columns\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "full_train_dict = df_full_train.to_dict(orient='records')\n",
    "X_full_train = dv.fit_transform(full_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c5c8949-cabe-4905-ba43-bde2efac6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def select_best_model(\n",
    "    estimator,\n",
    "    params,\n",
    "    X_full_train,\n",
    "    y_full_train,\n",
    "    random_state=None,\n",
    "    n_jobs=-1):\n",
    "\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator,\n",
    "        params,\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    search = rs.fit(X_full_train, y_full_train)\n",
    "    best_params = search.best_params_\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_score = search.best_score_\n",
    "    \n",
    "    return best_estimator, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "107c7822-94b1-4e18-9761-8f45c99fe944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "linear_regression_grid_search = GridSearchCV(\n",
    "    estimator=LinearRegression(),\n",
    "    param_grid=linear_regression_params,\n",
    "    n_jobs=-1)\n",
    "linear_regression_grid_search_fitted = linear_regression_grid_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_linear_regression_estimator = linear_regression_grid_search_fitted.best_estimator_\n",
    "best_linear_regression_params = linear_regression_grid_search_fitted.best_params_\n",
    "best_linear_regression_score = linear_regression_grid_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3a0c7f0-d81f-48c0-98dc-2aab114b1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=Lasso(),\n",
    "    param_grid=lasso_params,\n",
    "    n_jobs=-1)\n",
    "lasso_grid_search_fitted = lasso_grid_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_lasso_estimator = lasso_grid_search_fitted.best_estimator_\n",
    "best_lasso_params = lasso_grid_search_fitted.best_params_\n",
    "best_lasso_score = lasso_grid_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afe8bdec-a284-4ecc-b942-afdc6e090e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree_params = {\n",
    "    'criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    'random_state': [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "decision_tree_search = RandomizedSearchCV(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    param_distributions=decision_tree_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "decision_tree_search_fitted = decision_tree_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_decision_tree_estimator = decision_tree_search_fitted.best_estimator_\n",
    "best_decision_tree_params = decision_tree_search_fitted.best_params_\n",
    "best_decision_tree_score = decision_tree_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a69bb02-7d23-4a1f-b376-fa68389f76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 448, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan  0.50513747  0.69451628  0.48769607  0.27212195  0.55863088\n",
      " -0.00549691         nan  0.51147192         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_params = {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"oob_score\": [True, False],\n",
    "    \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    \"ccp_alpha\": [0.0, 0.1, 0.2],\n",
    "    \"random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "random_forest_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_distributions=random_forest_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "random_forest_search_fitted = random_forest_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_random_forest_estimator = random_forest_search_fitted.best_estimator_\n",
    "best_random_forest_params = random_forest_search_fitted.best_params_\n",
    "best_random_forest_score = random_forest_search_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4430f5b-e207-4be1-840a-201df5f56d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "adaboost_regressor_params = {\n",
    "  \"learning_rate\": [0.01, 0.1, 1],\n",
    "  \"n_estimators\": [10, 50, 100, 200],\n",
    "  \"loss\": [\"linear\", \"square\", \"exponential\"],\n",
    "  \"estimator\": [\n",
    "      DecisionTreeRegressor(),\n",
    "      RandomForestRegressor(),\n",
    "      # DecisionTreeRegressor(**best_decision_tree_params),\n",
    "      # RandomForestRegressor(**best_random_forest_params)\n",
    "  ],\n",
    "  \"random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "adaboost_regressor_search = RandomizedSearchCV(\n",
    "    estimator=AdaBoostRegressor(),\n",
    "    param_distributions=adaboost_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "adaboost_regressor_search_fitted = adaboost_regressor_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "best_adaboost_regressor_estimator = adaboost_regressor_search_fitted.best_estimator_\n",
    "best_adaboost_regressor_params = adaboost_regressor_search_fitted.best_params_\n",
    "best_adaboost_regressor_score = adaboost_regressor_search_fitted.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25ecc743-5ee3-4381-ba59-ff3ddeb5047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan  0.69237334         nan         nan  0.68853958 -0.72963775\n",
      "  0.67522997         nan  0.71545512  0.53028827]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gradientboost_regressor_params = {\n",
    "  \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "  \"n_estimators\": [50, 100, 200],\n",
    "  \"max_depth\": [3, 5, 7],\n",
    "  \"min_samples_split\": [2, 5, 10],\n",
    "  \"min_samples_leaf\": [1, 2, 4],\n",
    "  \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "  \"subsample\": [1.0, 0.8, 0.5],\n",
    "  \"loss\": [\"squared_error\", \"absolute_error\", \"huber\"],\n",
    "  \"alpha\": [0.5, 0.75, 0.9],\n",
    "  \"random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "gradientboost_regressor_search = RandomizedSearchCV(\n",
    "    estimator=GradientBoostingRegressor(),\n",
    "    param_distributions=gradientboost_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "gradientboost_regressor_search_fitted = gradientboost_regressor_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "\n",
    "gradientboost_regressor_estimator = gradientboost_regressor_search_fitted.best_estimator_\n",
    "gradientboost_regressor_params = gradientboost_regressor_search_fitted.best_params_\n",
    "gradientboost_regressor_score = gradientboost_regressor_search_fitted.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48530754-21e4-46ee-b4f4-7a4b34a26a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor_params = {\n",
    "    'hidden_layer_sizes': [(32,), (64,), (128,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'batch_size': ['auto', 200],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'power_t': [0.5, 1.0, 2.0],\n",
    "    'max_iter': [500, 1000, 1500],\n",
    "    'early_stopping': [True, False],\n",
    "    'validation_fraction': [0.2, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "mlp_regressor_search = RandomizedSearchCV(\n",
    "    estimator=MLPRegressor(),\n",
    "    param_distributions=mlp_regressor_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "mlp_regressor_search_fitted = mlp_regressor_search.fit(X_full_train, y_full_train)\n",
    "\n",
    "mlp_regressor_estimator = mlp_regressor_search_fitted.best_estimator_\n",
    "mlp_regressor_params = mlp_regressor_search_fitted.best_params_\n",
    "mlp_regressor_score = mlp_regressor_search_fitted.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baec7c1-8f8c-47c1-a3e3-27ca79b8c459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
