{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-07 18:02:53--  https://github.com/jelambrar96-datatalks/house-price-predictor/blob/main/dataset/train.csv\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv               [ <=>                ] 910.64K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-01-07 18:02:54 (21.1 MB/s) - ‘train.csv’ saved [932500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train.csv \"https://github.com/jelambrar96-datatalks/house-price-predictor/blob/main/dataset/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"../dataset/train.csv\"\n",
    "df_full = pd.read_csv(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert camelCase or PascalCase to snake_case\n",
    "def to_snake_case(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "df_full.columns = [to_snake_case(col) for col in df_full.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(\n",
    "    columns=[\"id\", \"alley\", \"pool_qc\", \"fence\", \"misc_feature\", \"mas_vnr_type\", \"fireplace_qu\", \"lot_frontage\"],\n",
    "    inplace=True\n",
    "    )\n",
    "df_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 73)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = \"sale_price\"\n",
    "\n",
    "df_full[TARGET_COLUMN] = np.log1p(df_full[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=RANDOM_SEED)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = (df_train[TARGET_COLUMN]).astype('int').values\n",
    "y_val = (df_val[TARGET_COLUMN]).astype('int').values\n",
    "y_test = (df_test[TARGET_COLUMN]).astype('int').values\n",
    "\n",
    "del df_train[TARGET_COLUMN]\n",
    "del df_val[TARGET_COLUMN]\n",
    "del df_test[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = df_train.select_dtypes(include=['number']).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n",
    "df_val[numerical_cols] = scaler.transform(df_val[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "dv = DictVectorizer(sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RegressionExperiment and init the class\n",
    "# from pycaret.regression import RegressionExperiment\n",
    "# exp = RegressionExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init setup on exp\n",
    "# exp.setup(df_train, target = y_train, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = exp.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, params, score_function):\n",
    "    \"\"\"\n",
    "    # Función para evaluar un conjunto de hiperparámetros\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('logistic', model(**params))\n",
    "    ])\n",
    "    \"\"\"\n",
    "    pipeline = model(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    score = score_function(y_val, y_val_pred)\n",
    "    return score, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def find_best_model(\n",
    "        Model,\n",
    "        parameter_grid,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        score_function,\n",
    "        verbose=False,\n",
    "        run_once=False):\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    parameter_labels = parameter_grid.keys()\n",
    "    parameter_values = parameter_grid.values()\n",
    "\n",
    "    for temp_parameter_iterable in product(*parameter_values):\n",
    "        params = { label:value for label, value in zip(parameter_labels, temp_parameter_iterable) }\n",
    "        if verbose:\n",
    "            print()\n",
    "            print(params)\n",
    "\n",
    "        # Evaluamos los parámetros\n",
    "        try:\n",
    "            score, model = evaluate_model(\n",
    "                Model, X_train, y_train, X_val, y_val, params, score_function\n",
    "            )\n",
    "        except ValueError as ve:\n",
    "            if verbose:\n",
    "                print(ve)\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"score_function: {score}\")\n",
    "        \n",
    "        # Actualizamos mejor modelo si es necesario\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "        \n",
    "        if run_once:\n",
    "            break\n",
    "\n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "def score_function_regression(y_true, y_pred, tag=\"rmse\"):\n",
    "    return -1 * root_mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "test_dict = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression trained\n"
     ]
    }
   ],
   "source": [
    "# model 1 lienar regression\n",
    "from mlmodels.skmodels import ZCLinearRegression\n",
    "\n",
    "parameter_grid_linear_regression = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'positive': [True, False],\n",
    "    'n_jobs': [-1, 1, 2, 4]\n",
    "}\n",
    "\n",
    "best_model_linear_regression, best_params_linear_regression, best_mrse_linear_regression = find_best_model(\n",
    "    ZCLinearRegression,\n",
    "    parameter_grid_linear_regression,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"linear regression trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso regression trained\n"
     ]
    }
   ],
   "source": [
    "from mlmodels.skmodels import ZCLassoRegression\n",
    "\n",
    "parameter_grid_lasso_regression = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "best_model_lasso_regression, best_params_lasso_regression, best_lasso_regression = find_best_model(\n",
    "    ZCLassoRegression,\n",
    "    parameter_grid_lasso_regression,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"lasso regression trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decition tree regression trained\n"
     ]
    }
   ],
   "source": [
    "from mlmodels.skmodels import ZCDecisionTreeRegressor\n",
    "\n",
    "parameter_grid_decision_tree_regressor = {\n",
    "    'criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    'random_state': [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "best_model_decision_tree_regressor, best_params_decision_tree_regressor, best_decision_tree_regressor = find_best_model(\n",
    "    ZCDecisionTreeRegressor,\n",
    "    parameter_grid_decision_tree_regressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"decition tree regression trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest_regressor trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/eda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:615: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from mlmodels.skmodels import ZCRandomForestRegressor\n",
    "\n",
    "parameter_grid_random_forest_regressor = {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.5, 1.0],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"oob_score\": [True, False],\n",
    "    \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    \"ccp_alpha\": [0.0, 0.1, 0.2],\n",
    "    \"random_state\": [RANDOM_SEED]\n",
    "  }\n",
    "\n",
    "best_model_random_forest_regressor, best_params_random_forest_regressor, best_random_forest_regressor = find_best_model(\n",
    "    ZCRandomForestRegressor,\n",
    "    parameter_grid_random_forest_regressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"random_forest_regressor trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso regression trained\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from mlmodels.skmodels import ZCAdaBoostRegressor\n",
    "\n",
    "\n",
    "parameter_grid_adaboost_regressor = {\n",
    "  \"learning_rate\": [0.1, 0.5, 1],\n",
    "  \"n_estimators\": [10, 50, 100, 200],\n",
    "  \"loss\": [\"linear\", \"square\", \"exponential\"],\n",
    "  \"estimator\": [DecisionTreeRegressor(), RandomForestRegressor()],\n",
    "  \"random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "best_model_adaboost_regressor, best_params_adaboost_regressor, best_adaboost_regressor = find_best_model(\n",
    "    ZCAdaBoostRegressor,\n",
    "    parameter_grid_adaboost_regressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"lasso regression trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grandient boost trained\n"
     ]
    }
   ],
   "source": [
    "from mlmodels.skmodels import ZCGradientBoostingRegressor\n",
    "\n",
    "parameter_grid_gradientboost_regressor = {\n",
    "  \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "  \"n_estimators\": [50, 100, 200],\n",
    "  \"max_depth\": [3, 5, 7],\n",
    "  \"min_samples_split\": [2, 5, 10],\n",
    "  \"min_samples_leaf\": [1, 2, 4],\n",
    "  \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "  \"subsample\": [1.0, 0.8, 0.5],\n",
    "  \"loss\": [\"squared_error\", \"absolute_error\", \"huber\"],\n",
    "  \"alpha\": [0.5, 0.75, 0.9],\n",
    "  \"random_state\": [RANDOM_SEED]\n",
    "}\n",
    "\n",
    "best_model_gradientboost_regressor, best_params_gradientboost_regressor, best_gradientboost_regressor = find_best_model(\n",
    "    ZCGradientBoostingRegressor,\n",
    "    parameter_grid_gradientboost_regressor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    score_function_regression,\n",
    "    verbose=False,\n",
    "    run_once=True\n",
    ")\n",
    "\n",
    "print(\"grandient boost trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "\n",
    "# model 1 lienar regression\n",
    "with mlflow.start_run(run_name=\"linear_regression\"):\n",
    "    best_model_linear_regression.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_linear_regression.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_linear_regression, \"model\")\n",
    "\n",
    "\n",
    "# model 2 lasso regression\n",
    "with mlflow.start_run(run_name=\"lasso_regression\"):\n",
    "    best_model_lasso_regression.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_lasso_regression.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_lasso_regression, \"model\")\n",
    "\n",
    "\n",
    "# model 3 decision tree regression\n",
    "with mlflow.start_run(run_name=\"decision_tree_regression\"):\n",
    "    best_model_decision_tree_regressor.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_decision_tree_regressor.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_decision_tree_regressor, \"model\")\n",
    "\n",
    "\n",
    "# model 4 random forest regression\n",
    "with mlflow.start_run(run_name=\"random_forest_regressor\"):\n",
    "    best_model_random_forest_regressor.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_random_forest_regressor.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_random_forest_regressor, \"model\")\n",
    "\n",
    "\n",
    "# model 5 adaboost regression\n",
    "with mlflow.start_run(run_name=\"adaboost_regression\"):\n",
    "    best_model_adaboost_regressor.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_adaboost_regressor.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_adaboost_regressor, \"model\")\n",
    "\n",
    "\n",
    "# model 6 gradient boost regression\n",
    "with mlflow.start_run(run_name=\"gradient_boost_regression\"):\n",
    "    best_model_gradientboost_regressor.fit(X_train, y_train)\n",
    "    y_test_pred = best_model_gradientboost_regressor.predict(X_test)\n",
    "    rmse = score_function_regression(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(best_model_gradientboost_regressor, \"model\")\n",
    "\n",
    "print(\"models trained and logged\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
